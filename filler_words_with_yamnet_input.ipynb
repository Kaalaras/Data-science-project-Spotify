{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fTb6OGGiRe5J",
   "metadata": {
    "id": "fTb6OGGiRe5J"
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow==2.8.0\n",
    "#or\n",
    "# !pip install tensorflow-gpu==2.8.0\n",
    "# import tensorflow as tf\n",
    "\n",
    "# !pip install tensorflow-io==0.25.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "NVaGezGIQi1l",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "id": "NVaGezGIQi1l",
    "outputId": "c3bbb5b3-7548-4826-e4c4-27216df145f8"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2Bnz23XsQKha",
   "metadata": {
    "id": "2Bnz23XsQKha"
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow_io \n",
    "# !pip install audb\n",
    "# !pip install audiofile\n",
    "# !pip install opensmile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50c49932",
   "metadata": {
    "id": "50c49932"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_io as tfio\n",
    "from tensorflow_io import audio\n",
    "import csv\n",
    "\n",
    "import librosa\n",
    "from scipy.io import wavfile\n",
    "from IPython.display import Audio\n",
    "\n",
    "from glob import glob\n",
    "import random\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import scipy\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import audb\n",
    "import audiofile\n",
    "import opensmile\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36591231",
   "metadata": {
    "id": "36591231"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "REPLICAS:  1\n"
     ]
    }
   ],
   "source": [
    "# Detect hardware, return appropriate distribution strategy\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    # strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d034cce",
   "metadata": {
    "id": "9d034cce"
   },
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\bapti\\KTH\\clip_wav\"\n",
    "test_path = r\"C:\\Users\\bapti\\KTH\\clip_wav\\test\"\n",
    "valid_path = r\"C:\\Users\\bapti\\KTH\\clip_wav\\validation\"\n",
    "train_path = r\"C:\\Users\\bapti\\KTH\\clip_wav\\train\"\n",
    "\n",
    "labels_path = r\"C:\\Users\\bapti\\KTH\\PodcastFillers.csv\"\n",
    "checkpoint_filepath = r\"C:\\Users\\bapti\\KTH\\checkpoints\\checkpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c0f441d",
   "metadata": {
    "id": "9c0f441d"
   },
   "outputs": [],
   "source": [
    "test_files = os.listdir(path = test_path)\n",
    "train_files = os.listdir(path =  train_path)\n",
    "valid_files = os.listdir(path =  valid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e96ae849",
   "metadata": {
    "id": "e96ae849",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install audb --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edec2a3a",
   "metadata": {
    "id": "edec2a3a"
   },
   "outputs": [],
   "source": [
    "# !pip install opensmile --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "464cbd4d",
   "metadata": {
    "id": "464cbd4d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "db = audb.load(\n",
    "    'emodb',\n",
    "    version='1.1.1',\n",
    "    format='wav',\n",
    "    mixdown=True,\n",
    "    sampling_rate=16000,\n",
    "    media='wav/03a01.*',  # load subset\n",
    "    full_path=False,\n",
    "    verbose=False,\n",
    ")\n",
    "# Process signal\n",
    "# Read first ten seconds of a file into memory.\n",
    "\n",
    "file = os.path.join(db.root, db.files[0])\n",
    "signal, sampling_rate = audiofile.read(\n",
    "    file,\n",
    "    duration=10,\n",
    "    always_2d=True,\n",
    ")\n",
    "# We set up a feature extractor for functionals of a pre-defined feature set.\n",
    "\n",
    "smile = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
    "    feature_level=opensmile.FeatureLevel.Functionals,\n",
    ")\n",
    "# smile.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a6069f8",
   "metadata": {
    "id": "8a6069f8"
   },
   "outputs": [],
   "source": [
    "sample_rate,wav_data = wavfile.read(test_path + \"/\"[0] + test_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e2dc977",
   "metadata": {
    "id": "0e2dc977",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9760284f",
   "metadata": {
    "id": "9760284f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow.audio\n",
    "factor = 16*2\n",
    "batch_size = 32*factor\n",
    "\n",
    "yamnet_model_handle = 'https://tfhub.dev/google/yamnet/1'\n",
    "yamnet_model = hub.load(yamnet_model_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a67de2f",
   "metadata": {
    "id": "6a67de2f"
   },
   "outputs": [],
   "source": [
    "def dataloader(path, labels_path,desired_sample_rate=16000):\n",
    "    @tf.function\n",
    "    def lecture_intern(filename, filepath):\n",
    "        \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\"\n",
    "        file_contents = tf.io.read_file(filepath + \"/\"[0] +filename)\n",
    "        wav, sample_rate = tf.audio.decode_wav(\n",
    "                      file_contents,\n",
    "              desired_channels=1)\n",
    "        wav = tf.squeeze(wav, axis=-1)\n",
    "        sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "        wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=desired_sample_rate)\n",
    "        return wav/tf.int16.max\n",
    "    \n",
    "\n",
    "    # def lecture_intern(filename, filepath):\n",
    "    #     sample_rate, wav_data = wavfile.read(filepath + \"/\"[0] + filename, 'rb')\n",
    "    #     # print(\"SAMPLE RATE : \", sample_rate)\n",
    "    #     # print(\"WAV_DATA : \", wav_data)\n",
    "    #     wav_data = ensure_sample_rate(sample_rate, wav_data,desired_sample_rate)\n",
    "    #     return wav_data/tf.int16.max\n",
    "\n",
    "    # def lecture_intern(filename, filepath):\n",
    "    #     wav, sample_rate = librosa.load(filepath+\"/\"[0]+filename,sr = desired_sample_rate)\n",
    "    #     return wav/tf.int16.max\n",
    "\n",
    "    @tf.function\n",
    "    def extract_embedding(wav_data):\n",
    "      ''' run YAMNet to extract embedding from the wav data '''\n",
    "      wav_data = tf.convert_to_tensor(wav_data)\n",
    "      scores, embeddings, spectrogram = yamnet_model(wav_data)\n",
    "#       num_embeddings = tf.shape(embeddings)[0]\n",
    "      return tf.reshape(embeddings,[1,2048])\n",
    "\n",
    "\n",
    "    def smile_intern(file):\n",
    "        return smile(file, desired_sample_rate).reshape((1,88))\n",
    "\n",
    "#     def ensure_sample_rate(original_sample_rate, waveform,\n",
    "#                            desired_sample_rate=desired_sample_rate):\n",
    "#           #Resample waveform if required.\n",
    "#         if original_sample_rate != desired_sample_rate:\n",
    "#             desired_length = int(round(float(len(waveform)) /original_sample_rate * desired_sample_rate))\n",
    "#             waveform = scipy.signal.resample(waveform, desired_length)\n",
    "#         return waveform\n",
    "      \n",
    "    def configure_for_performance(ds):\n",
    "        ds = ds.shuffle(buffer_size=1024)\n",
    "        ds = ds.batch(batch_size=batch_size)\n",
    "        ds = ds.repeat()\n",
    "        ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "        return ds\n",
    "    \n",
    "    \n",
    "    # test_path = test_path\n",
    "    # valid_path = valid_path\n",
    "    # train_path = train_path\n",
    "    \n",
    "    df_labels = pd.read_csv(labels_path)[[\"clip_name\",\"label_full_vocab\", \"confidence\", \"clip_split_subset\"]].head(100)\n",
    "    # print(df_labels)\n",
    "    Y = df_labels[\"label_full_vocab\"]\n",
    "    oe = OrdinalEncoder()\n",
    "    target = oe.fit_transform(Y.values.reshape(-1, 1)).ravel()\n",
    "    labels = tf.keras.utils.to_categorical(target, num_classes=13)\n",
    "    \n",
    "    y_test_ds = tf.data.Dataset.from_tensor_slices(labels[df_labels[\"clip_split_subset\"] == \"test\"])\n",
    "    y_valid_ds = tf.data.Dataset.from_tensor_slices(labels[df_labels[\"clip_split_subset\"] == \"validation\"])\n",
    "    y_train_ds = tf.data.Dataset.from_tensor_slices(labels[df_labels[\"clip_split_subset\"] == \"train\"])\n",
    "    \n",
    "    filenames_test = list(df_labels[df_labels[\"clip_split_subset\"] == \"test\"][\"clip_name\"])\n",
    "    filenames_valid = list(df_labels[df_labels[\"clip_split_subset\"] == \"validation\"][\"clip_name\"])\n",
    "    filenames_train = list(df_labels[df_labels[\"clip_split_subset\"] == \"train\"][\"clip_name\"])\n",
    "    \n",
    "    def lecture_intern_test(file):\n",
    "        return lecture_intern(file,test_path)\n",
    "    \n",
    "    def lecture_intern_valid(file):\n",
    "        return lecture_intern(file,valid_path)\n",
    "    \n",
    "    def lecture_intern_train(file):\n",
    "        return lecture_intern(file,train_path)\n",
    "\n",
    "    #.map(reformulate, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    # a = time.time()\n",
    "    # print(\"test_map\")\n",
    "    # x_test_map = list(map(lecture_intern_test,filenames_test))\n",
    "    # b = time.time()\n",
    "    # print(\"Done in :\",b-a, \"s\")\n",
    "    # print(\"test_smile_map\")\n",
    "    # x_test_smile_map = list(map(smile_intern, x_test_map))\n",
    "    # a = time.time()\n",
    "    # print(\"Done in :\",a-b, \"s\")\n",
    "    # print(\"test_ds\")\n",
    "    # x_test_ds = tf.data.Dataset.from_tensor_slices(x_test_map).map(extract_embedding, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    # b = time.time()\n",
    "    # print(\"Done in :\",b-a, \"s\")\n",
    "    # print(\"test_smile_ds\")\n",
    "    # x_test_smile_ds = tf.data.Dataset.from_tensor_slices(x_test_smile_map)\n",
    "    # a = time.time()\n",
    "    # print(\"Done in :\",a-b, \"s\":)\n",
    "\n",
    "\n",
    "    x_test_map = list(map(lecture_intern_test,filenames_test))\n",
    "    x_test_smile_map = list(map(smile_intern, x_test_map))\n",
    "    x_test_ds = tf.data.Dataset.from_tensor_slices(x_test_map).map(extract_embedding, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    x_test_smile_ds = tf.data.Dataset.from_tensor_slices(x_test_smile_map)\n",
    "\n",
    "    x_valid_map = list(map(lecture_intern_valid,filenames_valid))\n",
    "    x_valid_smile_map = list(map(smile_intern, x_valid_map))\n",
    "    x_valid_ds = tf.data.Dataset.from_tensor_slices(x_valid_map).map(extract_embedding, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    x_valid_smile_ds = tf.data.Dataset.from_tensor_slices(x_valid_smile_map)\n",
    "    \n",
    "    x_train_map = list(map(lecture_intern_train,filenames_train))\n",
    "    x_train_smile_map = list(map(smile_intern, x_train_map))\n",
    "    x_train_ds = tf.data.Dataset.from_tensor_slices(x_train_map).map(extract_embedding, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    x_train_smile_ds = tf.data.Dataset.from_tensor_slices(x_train_smile_map)\n",
    "\n",
    "    ds1_test = tf.data.Dataset.zip((x_test_ds, x_test_smile_ds))\n",
    "    ds_test = tf.data.Dataset.zip((ds1_test, y_test_ds))\n",
    "    ds_test = configure_for_performance(ds_test)\n",
    "\n",
    "    # ds_test = tf.data.Dataset.zip((x_test_ds, y_test_ds))\n",
    "    # ds_test = configure_for_performance(ds_test)\n",
    "    \n",
    "    ds1_valid = tf.data.Dataset.zip((x_valid_ds, x_valid_smile_ds))\n",
    "    ds_valid = tf.data.Dataset.zip((ds1_valid, y_valid_ds))\n",
    "    ds_valid = configure_for_performance(ds_valid)\n",
    "    \n",
    "    ds1_train = tf.data.Dataset.zip((x_train_ds, x_train_smile_ds))\n",
    "    ds_train = tf.data.Dataset.zip((ds1_train, y_train_ds))\n",
    "    ds_train = configure_for_performance(ds_train)\n",
    "    \n",
    "    # return  ds_test\n",
    "    \n",
    "    return ds_train, ds_valid, ds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11b3cecf",
   "metadata": {
    "id": "11b3cecf",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function dataloader.<locals>.lecture_intern at 0x0000026FA420C5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function dataloader.<locals>.lecture_intern at 0x0000026FA420C5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function dataloader.<locals>.lecture_intern at 0x0000026FA420C5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function dataloader.<locals>.lecture_intern at 0x0000026FA420C5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    }
   ],
   "source": [
    "ds_train, ds_valid, ds_test = dataloader(path, labels_path)\n",
    "# ds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "RDzEbUovPE0O",
   "metadata": {
    "id": "RDzEbUovPE0O"
   },
   "outputs": [],
   "source": [
    "# def ensure_sample_rate(original_sample_rate, waveform,\n",
    "#                        desired_sample_rate=16000):\n",
    "#     #Resample waveform if required.\n",
    "#     if original_sample_rate != desired_sample_rate:\n",
    "#         desired_length = int(round(float(len(waveform)) /original_sample_rate * desired_sample_rate))\n",
    "#         waveform = scipy.signal.resample(waveform, desired_length)\n",
    "#     return waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "mH_fJJNqPE0R",
   "metadata": {
    "id": "mH_fJJNqPE0R"
   },
   "outputs": [],
   "source": [
    "# sample_rate,wav_data = wavfile.read(test_path + \"/\"[0] + test_files[0])\n",
    "# wav_data = ensure_sample_rate(sample_rate, wav_data)/ tf.int16.max\n",
    "# print(wav_data)\n",
    "# print(sample_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0Av0C-ilVSoM",
   "metadata": {
    "id": "0Av0C-ilVSoM"
   },
   "outputs": [],
   "source": [
    "# score, embedding, spectrogram = yamnet_model(wav_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fRykFxmfACZH",
   "metadata": {
    "id": "fRykFxmfACZH"
   },
   "outputs": [],
   "source": [
    "# embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "UKNVjWVUfBZ9",
   "metadata": {
    "id": "UKNVjWVUfBZ9"
   },
   "outputs": [],
   "source": [
    "# wav_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fAhVL4KxfItS",
   "metadata": {
    "id": "fAhVL4KxfItS"
   },
   "outputs": [],
   "source": [
    "# smile_data = smile(wav_data,16000).reshape((88))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "wc0hTjVDV3Qw",
   "metadata": {
    "id": "wc0hTjVDV3Qw"
   },
   "outputs": [],
   "source": [
    "# dummy_data = [wav_data, smile_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "G1OYQ3X0VeEr",
   "metadata": {
    "id": "G1OYQ3X0VeEr"
   },
   "outputs": [],
   "source": [
    "def create_dummy():\n",
    "\n",
    "    input_yamnet = tf.keras.layers.Input(shape=(2048), dtype=tf.float32, name='audio', ragged = True)\n",
    "    input_yamnet = tf.reshape(input_yamnet, [-1,1,2048])\n",
    "#     input_yamnet = tf.keras.layers.BatchNormalization()(input_yamnet)\n",
    "    input_smile = tf.keras.layers.Input(shape=(88), dtype=tf.float32, name='smile', ragged = True)\n",
    "    input_smile = tf.reshape(input_smile, [-1,1,88])\n",
    "    \n",
    "\n",
    "\n",
    "    concat_layer = tf.keras.layers.Concatenate(axis = 2 )([input_smile , input_yamnet])\n",
    "\n",
    "    first_layer = tf.keras.layers.Dense(16, activation = \"selu\")(concat_layer)\n",
    "    first_layer =  tf.keras.layers.BatchNormalization()(first_layer)\n",
    "#     first_layer = tf.keras.layers.Dense(1024, activation = \"relu\")(concat_layer)\n",
    "#     first_layer =  tf.keras.layers.BatchNormalization()(first_layer)\n",
    "    \n",
    "#     first_layer = tf.keras.layers.Dense(512, activation = \"relu\")(first_layer)\n",
    "#     first_layer =  tf.keras.layers.BatchNormalization()(first_layer)\n",
    "#     first_layer = tf.keras.layers.Dense(128, activation = \"relu\")(first_layer)\n",
    "#     first_layer =  tf.keras.layers.BatchNormalization()(first_layer)\n",
    "\n",
    "    output = tf.keras.layers.Dense(13,activation = None, dtype='float32')(first_layer)\n",
    "    output = tf.keras.layers.BatchNormalization()(output)\n",
    "    output = tf.keras.layers.Activation(\"softmax\")(output)\n",
    "    output = tf.reshape(output, [-1,13])\n",
    "    # output = ReduceMeanLayer(axis=0, name='classifier')(output)\n",
    "    model = tf.keras.models.Model(inputs=[input_yamnet,input_smile], outputs= output)\n",
    "    # model = tf.keras.models.Model(inputs=input_segment, outputs= output)\n",
    "    model.compile(loss=\"categorical_crossentropy\",metrics=[\"accuracy\"],optimizer = \"RMSprop\")\n",
    "    return model\n",
    "\n",
    "dummy_model = create_dummy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49caa41e",
   "metadata": {
    "id": "49caa41e"
   },
   "outputs": [],
   "source": [
    "lr_min = 1e-5/factor\n",
    "lr_max = 1e-2/factor\n",
    "\n",
    "def my_cosine_decay(epoch,\n",
    "                    epoch_max=5,\n",
    "                    LR_START = 0.0001/2,\n",
    "                    LR_MAX =  lr_max,\n",
    "                    LR_MIN = lr_min,\n",
    "                    LR_RAMPUP_EPOCHS = 3,\n",
    "                    LR_SUSTAIN_EPOCHS = 0,\n",
    "                    LR_ALPHA_DECAY = .7\n",
    "                   ):\n",
    "    if epoch < LR_RAMPUP_EPOCHS:\n",
    "        learning_rate = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
    "    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
    "        learning_rate = LR_MAX\n",
    "    else:\n",
    "        cosine_decay=max(0.5*(1+np.cos(np.pi*((epoch-LR_RAMPUP_EPOCHS)/epoch_max))),LR_MIN)\n",
    "        decayed=(1-LR_ALPHA_DECAY)*cosine_decay+LR_ALPHA_DECAY\n",
    "        learning_rate=LR_MAX*decayed\n",
    "    return learning_rate\n",
    "\n",
    "def lr_decay(epoch,\n",
    "            LR_START = lr_max/2,\n",
    "            LR_MAX =  lr_max,\n",
    "            LR_MIN = lr_min,\n",
    "            LR_RAMPUP_EPOCHS = 3,\n",
    "            LR_SUSTAIN_EPOCHS = 0,\n",
    "            LR_ALPHA_DECAY = .05\n",
    "                   ):\n",
    "    learning_rate=max(LR_MAX*np.exp(-LR_ALPHA_DECAY*epoch), LR_MIN)\n",
    "    return learning_rate\n",
    "   \n",
    "\n",
    "def my_clr(epoch,\n",
    "           epoch_cycle = 8,\n",
    "           LR_MIN = lr_min,\n",
    "           LR_MAX = lr_max,\n",
    "           LR_ALPHA_DECAY = .9):\n",
    "    nb_cycle = epoch // epoch_cycle\n",
    "    k=0\n",
    "    while k < nb_cycle :\n",
    "        LR_MAX = (LR_MAX+ LR_MIN)*LR_ALPHA_DECAY\n",
    "        k += 1\n",
    "    if epoch % epoch_cycle < epoch_cycle//2 :\n",
    "        learning_rate = (LR_MAX - LR_MIN) / (epoch_cycle//2) * (epoch % (epoch_cycle//2)) + LR_MIN\n",
    "    else :\n",
    "        learning_rate = -(LR_MAX - LR_MIN) / (epoch_cycle//2) * (epoch % (epoch_cycle//2)) + LR_MAX\n",
    "    return learning_rate\n",
    "    \n",
    "lrfn=lambda epoch : my_clr(\n",
    "       epoch,\n",
    "        LR_MIN = lr_min,\n",
    "        LR_MAX = lr_max\n",
    "    )\n",
    "\n",
    "\n",
    "checkpoint_dir = os.path.dirname(checkpoint_filepath)\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)\n",
    "early_stopper = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=16,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd05203a",
   "metadata": {
    "id": "bd05203a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 6.25e-07.\n",
      "Epoch 1/1000\n",
      "18/18 [==============================] - 3s 118ms/step - loss: 2.9017 - accuracy: 0.0000e+00 - val_loss: 12.8566 - val_accuracy: 0.0000e+00 - lr: 6.2500e-07\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.00015671875.\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 2s 106ms/step - loss: 2.2178 - accuracy: 0.3111 - val_loss: 11.7324 - val_accuracy: 0.0000e+00 - lr: 1.5672e-04\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0003128125.\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 2s 105ms/step - loss: 1.5778 - accuracy: 0.6778 - val_loss: 12.0811 - val_accuracy: 0.0000e+00 - lr: 3.1281e-04\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.00046890625000000003.\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 1s 86ms/step - loss: 1.4731 - accuracy: 0.8111 - val_loss: 11.7241 - val_accuracy: 0.0000e+00 - lr: 4.6891e-04\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.000625.\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 2s 88ms/step - loss: 1.3661 - accuracy: 0.8444 - val_loss: 11.6606 - val_accuracy: 0.0000e+00 - lr: 6.2500e-04\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.00046890625000000003.\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 2s 91ms/step - loss: 1.2415 - accuracy: 0.8944 - val_loss: 11.8928 - val_accuracy: 0.0000e+00 - lr: 4.6891e-04\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0003128125.\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 1.1812 - accuracy: 0.9000 - val_loss: 11.4547 - val_accuracy: 0.0000e+00 - lr: 3.1281e-04\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.00015671874999999996.\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 2s 90ms/step - loss: 1.1474 - accuracy: 0.9000 - val_loss: 10.9705 - val_accuracy: 0.3333 - lr: 1.5672e-04\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 6.25e-07.\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 1.1413 - accuracy: 0.9000 - val_loss: 10.9229 - val_accuracy: 0.3333 - lr: 6.2500e-07\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.000141234375.\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 2s 91ms/step - loss: 1.1353 - accuracy: 0.9111 - val_loss: 10.8743 - val_accuracy: 0.3333 - lr: 1.4123e-04\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00028184375.\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 2s 88ms/step - loss: 1.1645 - accuracy: 0.9278 - val_loss: 12.1853 - val_accuracy: 0.0000e+00 - lr: 2.8184e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.000422453125.\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 1.1274 - accuracy: 0.9778 - val_loss: 16.1181 - val_accuracy: 0.0000e+00 - lr: 4.2245e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.0005630625.\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 2s 102ms/step - loss: 1.1602 - accuracy: 0.9833 - val_loss: 10.7487 - val_accuracy: 0.3333 - lr: 5.6306e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.000422453125.\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 1s 83ms/step - loss: 1.0823 - accuracy: 0.9778 - val_loss: 16.1181 - val_accuracy: 0.0000e+00 - lr: 4.2245e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.00028184375.\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 1.0277 - accuracy: 1.0000 - val_loss: 16.1181 - val_accuracy: 0.0000e+00 - lr: 2.8184e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.00014123437499999998.\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 2s 90ms/step - loss: 1.0015 - accuracy: 1.0000 - val_loss: 16.1181 - val_accuracy: 0.0000e+00 - lr: 1.4123e-04\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 6.25e-07.\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 0.9983 - accuracy: 1.0000 - val_loss: 16.1181 - val_accuracy: 0.0000e+00 - lr: 6.2500e-07\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00012729843750000001.\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 2s 89ms/step - loss: 0.9944 - accuracy: 1.0000 - val_loss: 13.1916 - val_accuracy: 0.0000e+00 - lr: 1.2730e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.000253971875.\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 1.0037 - accuracy: 1.0000 - val_loss: 14.1802 - val_accuracy: 0.0000e+00 - lr: 2.5397e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00038064531250000004.\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 0.9949 - accuracy: 1.0000 - val_loss: 16.1181 - val_accuracy: 0.0000e+00 - lr: 3.8065e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.00050731875.\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 2s 89ms/step - loss: 0.9912 - accuracy: 0.9944 - val_loss: 15.5451 - val_accuracy: 0.0000e+00 - lr: 5.0732e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.00038064531250000004.\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 1s 86ms/step - loss: 0.9380 - accuracy: 1.0000 - val_loss: 10.9229 - val_accuracy: 0.0000e+00 - lr: 3.8065e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000253971875.\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 2s 92ms/step - loss: 0.9202 - accuracy: 1.0000 - val_loss: 9.1187 - val_accuracy: 0.0000e+00 - lr: 2.5397e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.00012729843749999996.\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 2s 90ms/step - loss: 0.9024 - accuracy: 1.0000 - val_loss: 8.1679 - val_accuracy: 0.3333 - lr: 1.2730e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 6.25e-07.\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 2s 90ms/step - loss: 0.8977 - accuracy: 1.0000 - val_loss: 7.8789 - val_accuracy: 0.3333 - lr: 6.2500e-07\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.00011475609375000002.\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 2s 89ms/step - loss: 0.8978 - accuracy: 1.0000 - val_loss: 10.6015 - val_accuracy: 0.0000e+00 - lr: 1.1476e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.00022888718750000003.\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 2s 92ms/step - loss: 0.9007 - accuracy: 1.0000 - val_loss: 16.1181 - val_accuracy: 0.0000e+00 - lr: 2.2889e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.00034301828125.\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 2s 92ms/step - loss: 0.8976 - accuracy: 1.0000 - val_loss: 16.1181 - val_accuracy: 0.0000e+00 - lr: 3.4302e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.00045714937500000003.\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 2s 107ms/step - loss: 0.8993 - accuracy: 1.0000 - val_loss: 12.5512 - val_accuracy: 0.0000e+00 - lr: 4.5715e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.00034301828125.\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 2s 89ms/step - loss: 0.8573 - accuracy: 1.0000 - val_loss: 16.1181 - val_accuracy: 0.0000e+00 - lr: 3.4302e-04\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0002288871875.\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 2s 92ms/step - loss: 0.8391 - accuracy: 1.0000 - val_loss: 11.6290 - val_accuracy: 0.0000e+00 - lr: 2.2889e-04\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00011475609374999999.\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 2s 91ms/step - loss: 0.8263 - accuracy: 1.0000 - val_loss: 6.7067 - val_accuracy: 0.0000e+00 - lr: 1.1476e-04\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 6.25e-07.\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 2s 91ms/step - loss: 0.8228 - accuracy: 1.0000 - val_loss: 5.6882 - val_accuracy: 0.0000e+00 - lr: 6.2500e-07\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.00010346798437500001.\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 0.8227 - accuracy: 1.0000 - val_loss: 2.0444 - val_accuracy: 0.3333 - lr: 1.0347e-04\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.00020631096875000003.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 0.8244 - accuracy: 1.0000 - val_loss: 16.1181 - val_accuracy: 0.0000e+00 - lr: 2.0631e-04\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.000309153953125.\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 2s 92ms/step - loss: 0.8203 - accuracy: 1.0000 - val_loss: 16.1181 - val_accuracy: 0.0000e+00 - lr: 3.0915e-04\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0004119969375.\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 1s 82ms/step - loss: 0.8133 - accuracy: 1.0000 - val_loss: 16.1181 - val_accuracy: 0.0000e+00 - lr: 4.1200e-04\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.000309153953125.\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 0.7872 - accuracy: 1.0000 - val_loss: 16.1181 - val_accuracy: 0.0000e+00 - lr: 3.0915e-04\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.00020631096875.\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 0.7726 - accuracy: 1.0000 - val_loss: 16.1181 - val_accuracy: 0.0000e+00 - lr: 2.0631e-04\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.00010346798437500001.\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 0.7645 - accuracy: 1.0000 - val_loss: 16.1181 - val_accuracy: 0.0000e+00 - lr: 1.0347e-04\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 6.25e-07.\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 2s 100ms/step - loss: 0.7618 - accuracy: 1.0000 - val_loss: 16.1181 - val_accuracy: 0.0000e+00 - lr: 6.2500e-07\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 9.33086859375e-05.\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 2s 90ms/step - loss: 0.7611 - accuracy: 1.0000 - val_loss: 16.1181 - val_accuracy: 0.0000e+00 - lr: 9.3309e-05\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.000185992371875.\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 0.7600 - accuracy: 1.0000 - val_loss: 16.1181 - val_accuracy: 0.0000e+00 - lr: 1.8599e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.00027867605781249996.\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 2s 90ms/step - loss: 0.7587 - accuracy: 1.0000 - val_loss: 16.1181 - val_accuracy: 0.0000e+00 - lr: 2.7868e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.00037135974375.\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 2s 88ms/step - loss: 0.7570 - accuracy: 1.0000 - val_loss: 16.1181 - val_accuracy: 0.0000e+00 - lr: 3.7136e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.00027867605781249996.\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 2s 88ms/step - loss: 0.7315 - accuracy: 1.0000 - val_loss: 16.1181 - val_accuracy: 0.0000e+00 - lr: 2.7868e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.00018599237187499998.\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 2s 90ms/step - loss: 0.7185 - accuracy: 1.0000 - val_loss: 16.1181 - val_accuracy: 0.0000e+00 - lr: 1.8599e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 9.33086859375e-05.\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 0.7127 - accuracy: 1.0000 - val_loss: 16.1181 - val_accuracy: 0.0000e+00 - lr: 9.3309e-05\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 6.25e-07.\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 0.7101 - accuracy: 1.0000 - val_loss: 16.1181 - val_accuracy: 0.0000e+00 - lr: 6.2500e-07\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 8.416531734375e-05.\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 2s 89ms/step - loss: 0.7097 - accuracy: 1.0000 - val_loss: 16.1181 - val_accuracy: 0.0000e+00 - lr: 8.4165e-05\n",
      "Epoch 50: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = dummy_model.fit(x = ds_test,validation_data = ds_train, validation_steps=int(len(train_files)/batch_size) ,epochs = 1000, callbacks = [lr_callback, early_stopper], steps_per_epoch = int(len(test_files)/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a3c75b1a",
   "metadata": {
    "id": "a3c75b1a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(np.arange(1,len(history.history[\"loss\"]) + 1),history.history[\"loss\"], color=\"blue\")\n",
    "plt.plot(np.arange(1,len(history.history[\"val_loss\"]) + 1),history.history[\"val_loss\"], color=\"orange\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae0b834",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dummy_model.evaluate(ds_test,steps=int(len(test_files)/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c9c4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model.evaluate(ds_valid,steps=int(len(valid_files)/batch_size))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
